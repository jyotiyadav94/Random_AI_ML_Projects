{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68e91697f32d4877b89fcedcc0a907fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd7fb982c94449ff99d6d8eb70c64eb5",
              "IPY_MODEL_d61e7ef3ca844178951902882611d6ec",
              "IPY_MODEL_ed12c6da27e243e5923451a8e154529b"
            ],
            "layout": "IPY_MODEL_fa5fe956945743e7ac50c2fef4b76cc1"
          }
        },
        "bd7fb982c94449ff99d6d8eb70c64eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3242a29575d4775be97f16025da73db",
            "placeholder": "​",
            "style": "IPY_MODEL_60bc7b06f5dd4f6cbda39cdc9e4cf9a6",
            "value": "  0%"
          }
        },
        "d61e7ef3ca844178951902882611d6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b310db2544a747129f5a466fa531d787",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_145f76edbb9b41559868b94842b700cb",
            "value": 0
          }
        },
        "ed12c6da27e243e5923451a8e154529b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6153110757d4d9dada32b53e78f564e",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb4b499ae814d5ba38b82fca808e2b0",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "fa5fe956945743e7ac50c2fef4b76cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3242a29575d4775be97f16025da73db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bc7b06f5dd4f6cbda39cdc9e4cf9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b310db2544a747129f5a466fa531d787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145f76edbb9b41559868b94842b700cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6153110757d4d9dada32b53e78f564e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb4b499ae814d5ba38b82fca808e2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q datasets seqeval\n",
        "!python -m pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install pyyaml>=5.1\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7QGpwHy2G5c",
        "outputId": "bb3ff686-f7a2-472a-a804-741392625f33"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import LayoutLMv2Tokenizer, LayoutLMv2ForTokenClassification, LayoutLMv2Config\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BqwKTIyu2ECS"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "5cNXCDfZnUPE"
      },
      "outputs": [],
      "source": [
        "# from urllib2 import Request, urlopen\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# reading the JSON data using json.load()\n",
        "file = '/content/2.json'\n",
        "\n",
        "df = pd.read_json(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "iFLoKl1eoJiN",
        "outputId": "4f12dea9-de82-4112-fed8-3b525c6506f3"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   ocr  id                                               bbox  \\\n",
              "0  /content/data/1.png   1  [[15.466666666666667, 15.457115928369463, 35.4...   \n",
              "1  /content/data/2.png   4  [[15.466666666666667, 15.174363807728557, 35.6...   \n",
              "\n",
              "                                               label  \\\n",
              "0  [produttore, Unit.Loc., Orario_richiesta, Data...   \n",
              "1  [produttore, Unit.Loc., Data_richiesta, Orario...   \n",
              "\n",
              "                                       transcription  annotator  \\\n",
              "0  [ SPAZIO SOC COO, Via S. Agostino, 2 51100 PIS...          1   \n",
              "1  [ALSTOM FERROVIA SPA, FIRENZE -Via del Romito ...          1   \n",
              "\n",
              "   annotation_id                       created_at  \\\n",
              "0              1 2022-06-14 09:57:19.654695+00:00   \n",
              "1              4 2022-06-14 11:36:49.515327+00:00   \n",
              "\n",
              "                        updated_at  lead_time  \n",
              "0 2022-06-14 16:07:17.971902+00:00  25734.315  \n",
              "1 2022-06-14 12:43:02.012909+00:00  13478.754  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bb8aed8-717e-4e47-b198-c5584b7b536f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ocr</th>\n",
              "      <th>id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>label</th>\n",
              "      <th>transcription</th>\n",
              "      <th>annotator</th>\n",
              "      <th>annotation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>lead_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/1.png</td>\n",
              "      <td>1</td>\n",
              "      <td>[[15.466666666666667, 15.457115928369463, 35.4...</td>\n",
              "      <td>[produttore, Unit.Loc., Orario_richiesta, Data...</td>\n",
              "      <td>[ SPAZIO SOC COO, Via S. Agostino, 2 51100 PIS...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-06-14 09:57:19.654695+00:00</td>\n",
              "      <td>2022-06-14 16:07:17.971902+00:00</td>\n",
              "      <td>25734.315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/2.png</td>\n",
              "      <td>4</td>\n",
              "      <td>[[15.466666666666667, 15.174363807728557, 35.6...</td>\n",
              "      <td>[produttore, Unit.Loc., Data_richiesta, Orario...</td>\n",
              "      <td>[ALSTOM FERROVIA SPA, FIRENZE -Via del Romito ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-06-14 11:36:49.515327+00:00</td>\n",
              "      <td>2022-06-14 12:43:02.012909+00:00</td>\n",
              "      <td>13478.754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bb8aed8-717e-4e47-b198-c5584b7b536f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bb8aed8-717e-4e47-b198-c5584b7b536f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bb8aed8-717e-4e47-b198-c5584b7b536f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropped = ['annotator','annotation_id','created_at','updated_at','lead_time']\n",
        "data = df.drop(dropped,axis=1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "m_RUCRLZpa7y",
        "outputId": "07d63e6c-5ef9-42cb-a530-a9f89be37ce7"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   ocr  id                                               bbox  \\\n",
              "0  /content/data/1.png   1  [[15.466666666666667, 15.457115928369463, 35.4...   \n",
              "1  /content/data/2.png   4  [[15.466666666666667, 15.174363807728557, 35.6...   \n",
              "\n",
              "                                               label  \\\n",
              "0  [produttore, Unit.Loc., Orario_richiesta, Data...   \n",
              "1  [produttore, Unit.Loc., Data_richiesta, Orario...   \n",
              "\n",
              "                                       transcription  \n",
              "0  [ SPAZIO SOC COO, Via S. Agostino, 2 51100 PIS...  \n",
              "1  [ALSTOM FERROVIA SPA, FIRENZE -Via del Romito ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b81010a0-ba5d-4c51-854c-d8ec42afaa48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ocr</th>\n",
              "      <th>id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>label</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/1.png</td>\n",
              "      <td>1</td>\n",
              "      <td>[[15.466666666666667, 15.457115928369463, 35.4...</td>\n",
              "      <td>[produttore, Unit.Loc., Orario_richiesta, Data...</td>\n",
              "      <td>[ SPAZIO SOC COO, Via S. Agostino, 2 51100 PIS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/2.png</td>\n",
              "      <td>4</td>\n",
              "      <td>[[15.466666666666667, 15.174363807728557, 35.6...</td>\n",
              "      <td>[produttore, Unit.Loc., Data_richiesta, Orario...</td>\n",
              "      <td>[ALSTOM FERROVIA SPA, FIRENZE -Via del Romito ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b81010a0-ba5d-4c51-854c-d8ec42afaa48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b81010a0-ba5d-4c51-854c-d8ec42afaa48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b81010a0-ba5d-4c51-854c-d8ec42afaa48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['imageWidth'] = '1901'\n",
        "data['imageHeight'] = '2690'"
      ],
      "metadata": {
        "id": "NaNJt69qcZzm"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns = {'ocr':'image_path', 'transcription':'words'}, inplace = True)\n",
        "\n",
        "  #  \"original_width\": 1901,\n",
        "  #       \"original_height\": 2690"
      ],
      "metadata": {
        "id": "ecgt1GxZqNZn"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "gUfGmPPydmID",
        "outputId": "f98a6711-69ef-484d-f61b-87464c93fbe7"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            image_path  id                                               bbox  \\\n",
              "0  /content/data/1.png   1  [[15.466666666666667, 15.457115928369463, 35.4...   \n",
              "1  /content/data/2.png   4  [[15.466666666666667, 15.174363807728557, 35.6...   \n",
              "\n",
              "                                               label  \\\n",
              "0  [produttore, Unit.Loc., Orario_richiesta, Data...   \n",
              "1  [produttore, Unit.Loc., Data_richiesta, Orario...   \n",
              "\n",
              "                                               words imageWidth imageHeight  \n",
              "0  [ SPAZIO SOC COO, Via S. Agostino, 2 51100 PIS...       1901        2690  \n",
              "1  [ALSTOM FERROVIA SPA, FIRENZE -Via del Romito ...       1901        2690  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3dd08f95-8da4-4ce4-8ec5-ff0f48da1020\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>label</th>\n",
              "      <th>words</th>\n",
              "      <th>imageWidth</th>\n",
              "      <th>imageHeight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/1.png</td>\n",
              "      <td>1</td>\n",
              "      <td>[[15.466666666666667, 15.457115928369463, 35.4...</td>\n",
              "      <td>[produttore, Unit.Loc., Orario_richiesta, Data...</td>\n",
              "      <td>[ SPAZIO SOC COO, Via S. Agostino, 2 51100 PIS...</td>\n",
              "      <td>1901</td>\n",
              "      <td>2690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/2.png</td>\n",
              "      <td>4</td>\n",
              "      <td>[[15.466666666666667, 15.174363807728557, 35.6...</td>\n",
              "      <td>[produttore, Unit.Loc., Data_richiesta, Orario...</td>\n",
              "      <td>[ALSTOM FERROVIA SPA, FIRENZE -Via del Romito ...</td>\n",
              "      <td>1901</td>\n",
              "      <td>2690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dd08f95-8da4-4ce4-8ec5-ff0f48da1020')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3dd08f95-8da4-4ce4-8ec5-ff0f48da1020 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3dd08f95-8da4-4ce4-8ec5-ff0f48da1020');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data.words)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljsmaIrie0FX",
        "outputId": "9ab7e4a9-f9b1-4200-afa5-c4f8ef91d311"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data.words[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s3BLe8Td-cR",
        "outputId": "9cc759cd-c6d0-42c5-b225-0ab3a4ee87b1"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data\n",
        "data.to_pickle(\"/content/data.pkl\")"
      ],
      "metadata": {
        "id": "l-6zhkJsqXd-"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.to_csv('/content/data.csv')"
      ],
      "metadata": {
        "id": "Yycw_kwqs4fa"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data=pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "F4pbj0k0s9En"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['bbox']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfdqraTwoqTl",
        "outputId": "f300d0a0-7b67-4814-8b2a-137edc487fc9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [[15.466666666666667, 15.457115928369463, 35.4...\n",
              "1    [[15.466666666666667, 15.174363807728557, 35.6...\n",
              "Name: bbox, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class data_config:\n",
        "    labels = np.unique([item for sublist in data.label for item in sublist]).tolist()\n",
        "    #labels = sum([[\"B-\" + item, \"I-\" + item] for item in np.unique(labels)], [])\n",
        "    labels = [\"B-\" + item for item in np.unique(labels)]\n",
        "    num_labels = len(labels)\n",
        "    id2label = {v: k for v, k in enumerate(labels)}\n",
        "    label2id = {k: v for v, k in enumerate(labels)}"
      ],
      "metadata": {
        "id": "efza1yzH15JL"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'microsoft/layoutlmv2-base-uncased'\n",
        "config = LayoutLMv2Config.from_pretrained(model_path, num_labels=data_config.num_labels, id2label = data_config.id2label, label2id = data_config.label2id)\n",
        "tokenizer = LayoutLMv2Tokenizer.from_pretrained(model_path)\n",
        "model = LayoutLMv2ForTokenClassification.from_pretrained(model_path, config = config)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "cUQbwQ6z3cYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2920f38e-1205-47ae-ad27-56eb4c1a81d1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/layoutlmv2-base-uncased were not used when initializing LayoutLMv2ForTokenClassification: ['layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked']\n",
            "- This IS expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv2-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LayoutLMv2ForTokenClassification(\n",
              "  (layoutlmv2): LayoutLMv2Model(\n",
              "    (embeddings): LayoutLMv2Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (x_position_embeddings): Embedding(1024, 128)\n",
              "      (y_position_embeddings): Embedding(1024, 128)\n",
              "      (h_position_embeddings): Embedding(1024, 128)\n",
              "      (w_position_embeddings): Embedding(1024, 128)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (visual): LayoutLMv2VisualBackbone(\n",
              "      (backbone): FPN(\n",
              "        (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (top_block): LastLevelMaxPool()\n",
              "        (bottom_up): ResNet(\n",
              "          (stem): BasicStem(\n",
              "            (conv1): Conv2d(\n",
              "              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
              "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
              "            )\n",
              "          )\n",
              "          (res2): Sequential(\n",
              "            (0): BottleneckBlock(\n",
              "              (shortcut): Conv2d(\n",
              "                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv1): Conv2d(\n",
              "                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (1): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (2): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (res3): Sequential(\n",
              "            (0): BottleneckBlock(\n",
              "              (shortcut): Conv2d(\n",
              "                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv1): Conv2d(\n",
              "                256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (1): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (2): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (3): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (res4): Sequential(\n",
              "            (0): BottleneckBlock(\n",
              "              (shortcut): Conv2d(\n",
              "                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv1): Conv2d(\n",
              "                512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (1): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (2): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (3): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (4): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (5): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (6): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (7): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (8): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (9): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (10): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (11): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (12): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (13): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (14): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (15): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (16): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (17): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (18): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (19): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (20): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (21): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (22): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (res5): Sequential(\n",
              "            (0): BottleneckBlock(\n",
              "              (shortcut): Conv2d(\n",
              "                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv1): Conv2d(\n",
              "                1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (1): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (2): BottleneckBlock(\n",
              "              (conv1): Conv2d(\n",
              "                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv2): Conv2d(\n",
              "                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "              (conv3): Conv2d(\n",
              "                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pool): AdaptiveAvgPool2d(output_size=[7, 7])\n",
              "    )\n",
              "    (visual_proj): Linear(in_features=256, out_features=768, bias=True)\n",
              "    (visual_LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (visual_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (encoder): LayoutLMv2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): LayoutLMv2Layer(\n",
              "          (attention): LayoutLMv2Attention(\n",
              "            (self): LayoutLMv2SelfAttention(\n",
              "              (qkv_linear): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
              "      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
              "      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
              "    )\n",
              "    (pooler): LayoutLMv2Pooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='/content/'\n",
        "torch.save(model.state_dict(), PATH +'layoutlm_EuroCoorp.pt')"
      ],
      "metadata": {
        "id": "A8wa7K22YOV1"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import LayoutLMv2Tokenizer, LayoutLMv2ForTokenClassification, LayoutLMv2Config\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def normalize_box(box, width, height):\n",
        "    width = int(width)\n",
        "    height = int(height)\n",
        "    # [ <class 'str'> 1901 <class 'int'>\n",
        "    # print(\"YYYY: \", box,'*',type(box[0]),'*',  width,'*', type(width) ,'*')\n",
        "    return [\n",
        "         int(1000 * (int(box[0]) / width)),\n",
        "         int(1000 * (int(box[1]) / height)),\n",
        "         int(1000 * (int(box[2]) / width)),\n",
        "         int(1000 * (int(box[3]) / height)),\n",
        "     ]\n",
        "\n",
        "def de_normalize(box, width, height):\n",
        "  return [\n",
        "          int((width * box[0])/1000),\n",
        "          int((height * box[1])/1000),\n",
        "          int((width * box[2])/1000),\n",
        "          int((height * box[3])/1000)\n",
        "  ]\n",
        "\n",
        "def resize_and_align_bounding_box(bbox, original_image, target_size):\n",
        "    x_, y_ = original_image.size\n",
        "    x_scale = target_size / x_ \n",
        "    y_scale = target_size / y_\n",
        "    origLeft, origTop, origRight, origBottom = tuple(bbox)\n",
        "    x = int(np.round(origLeft * x_scale))\n",
        "    y = int(np.round(origTop * y_scale))\n",
        "    xmax = int(np.round(origRight * x_scale))\n",
        "    ymax = int(np.round(origBottom * y_scale)) \n",
        "    return [x-0.5, y-0.5, xmax+0.5, ymax+0.5]\n",
        " \n",
        "class InvoiceDataSet(Dataset):\n",
        "    \"\"\"LayoutLM dataset with visual features.\"\"\"\n",
        " \n",
        "    def __init__(self, df, tokenizer, max_length, target_size, train=True):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_length\n",
        "        self.target_size = target_size\n",
        "        self.pad_token_box = [0, 0, 0, 0]\n",
        "        self.train = train\n",
        " \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.df.iloc[idx,:].to_dict()        \n",
        "        #base_path = data_config.base_image_path\n",
        "        original_image = Image.open(os.path.join('/content/data/' , item[\"image_path\"])).convert(\"RGB\")\n",
        "        # resize to target size (to be provided to the pre-trained backbone)\n",
        "        resized_image = original_image.resize((self.target_size, self.target_size))\n",
        "        # first, read in annotations at word-level (words, bounding boxes, labels)\n",
        "        words = item[\"words\"]\n",
        "        # print(words)\n",
        "        # print(\"IN GETITEM XXX: \", type(words), type(words[0]))\n",
        "        unnormalized_word_boxes = item[\"bbox\"]\n",
        "        # print(unnormalized_word_boxes)\n",
        "\n",
        "        # print(\"IN boxes XXX: \", type(unnormalized_word_boxes), type(unnormalized_word_boxes[0]))\n",
        "        word_labels = item[\"label\"]\n",
        "        # print(word_labels)\n",
        "\n",
        "        width = item[\"imageWidth\"]\n",
        "        height = item[\"imageHeight\"]\n",
        "        normalized_word_boxes = [normalize_box(bbox, width, height) for bbox in unnormalized_word_boxes]\n",
        "        # print('normalized_word_boxes',normalized_word_boxes)\n",
        "        assert len(words) == len(normalized_word_boxes)\n",
        " \n",
        "        # next, transform to token-level (input_ids, attention_mask, token_type_ids, bbox, labels)\n",
        "        token_boxes = []\n",
        "        unnormalized_token_boxes = []\n",
        "        token_labels = []\n",
        "        for word, unnormalized_box, box, label in zip(words, unnormalized_word_boxes, normalized_word_boxes, word_labels):\n",
        "            word_tokens = self.tokenizer.tokenize(word)\n",
        "            unnormalized_token_boxes.extend(unnormalized_box for _ in range(len(word_tokens)))\n",
        "            token_boxes.extend(box for _ in range(len(word_tokens)))\n",
        "            # label first token as B-label (beginning), label all remaining tokens as I-label (inside)\n",
        "            for i in range(len(word_tokens)):\n",
        "                if  1 == 1:#i == 0:\n",
        "                    token_labels.extend(['B-' + label])\n",
        "                else:\n",
        "                    token_labels.extend(['I-' + label])\n",
        "        \n",
        "        # Truncation of token_boxes + token_labels\n",
        "        special_tokens_count = 2 \n",
        "        if len(token_boxes) > self.max_seq_length - special_tokens_count:\n",
        "            token_boxes = token_boxes[: (self.max_seq_length - special_tokens_count)]\n",
        "            unnormalized_token_boxes = unnormalized_token_boxes[: (self.max_seq_length - special_tokens_count)]\n",
        "            token_labels = token_labels[: (self.max_seq_length - special_tokens_count)]\n",
        "        \n",
        "        # add bounding boxes and labels of cls + sep tokens\n",
        "        token_boxes = [self.pad_token_box] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
        "        unnormalized_token_boxes = [self.pad_token_box] + unnormalized_token_boxes + [[1000, 1000, 1000, 1000]]\n",
        "        token_labels = [-100] + token_labels + [-100]\n",
        "        print('token_labels',token_labels)\n",
        "        # return token_labels\n",
        "\n",
        "        encoding = self.tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
        "        # Padding of token_boxes up the bounding boxes to the sequence length.\n",
        "        print('encoding',encoding)\n",
        "        input_ids = self.tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
        "        padding_length = self.max_seq_length - len(input_ids)\n",
        "        token_boxes += [self.pad_token_box] * padding_length\n",
        "        unnormalized_token_boxes += [self.pad_token_box] * padding_length\n",
        "        token_labels += [-100] * padding_length\n",
        "        encoding['bbox'] = token_boxes\n",
        "        encoding['labels'] = token_labels\n",
        " \n",
        "        assert len(encoding['input_ids']) == self.max_seq_length\n",
        "        assert len(encoding['attention_mask']) == self.max_seq_length\n",
        "        assert len(encoding['token_type_ids']) == self.max_seq_length\n",
        "        assert len(encoding['bbox']) == self.max_seq_length\n",
        "        assert len(encoding['labels']) == self.max_seq_length\n",
        " \n",
        "        encoding['resized_image'] = ToTensor()(resized_image)\n",
        "        # rescale and align the bounding boxes to match the resized image size (typically 224x224) \n",
        "        encoding['resized_and_aligned_bounding_boxes'] = [resize_and_align_bounding_box(bbox, original_image, self.target_size) for bbox in unnormalized_token_boxes]\n",
        "        #encoding['unnormalized_token_boxes'] = unnormalized_token_boxes\n",
        "        \n",
        "        # finally, convert everything to PyTorch tensors \n",
        "        for k,v in encoding.items():\n",
        "            if k == 'labels':\n",
        "                label_indices = []\n",
        "                # convert labels from string to indices\n",
        "                for label in encoding[k]:\n",
        "                    if label != -100:\n",
        "                        label_indices.append(data_config.label2id[label])\n",
        "                    else:\n",
        "                        label_indices.append(label)\n",
        "                encoding[k] = label_indices\n",
        "            encoding[k] = torch.as_tensor(encoding[k])\n",
        "        print(encoding)\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "Gqyw_D5R9gFX"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, valid = train_test_split(data, test_size = 0.2)\n",
        "\n",
        "train_dataset = InvoiceDataSet(df = train, tokenizer = tokenizer, max_length = 512, target_size = 224, train=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=5)\n",
        "\n",
        "valid_dataset = InvoiceDataSet(df = valid, tokenizer = tokenizer, max_length = 512, target_size = 224, train=False)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=5)"
      ],
      "metadata": {
        "id": "0FZWiv_XYktZ"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "import torch\n",
        "\n",
        "\n",
        "def train_fn(train_dataloader, model, optimizer):\n",
        "    tk0 = tqdm(train_dataloader, total = len(train_dataloader))\n",
        "    for bi, batch in enumerate(tk0):\n",
        "        input_ids=batch['input_ids'].to(device)\n",
        "        bbox=batch['bbox'].to(device)\n",
        "        attention_mask=batch['attention_mask'].to(device)\n",
        "        token_type_ids=batch['token_type_ids'].to(device)\n",
        "        labels=batch['labels'].to(device)\n",
        "        resized_images = batch['resized_image'].to(device) \n",
        "        resized_and_aligned_bounding_boxes = batch['resized_and_aligned_bounding_boxes'].to(device) \n",
        "        outputs = model(image = resized_images,input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "def eval_fn(eval_dataloader, model):\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    model.eval()\n",
        "    tk0 = tqdm(eval_dataloader, total = len(eval_dataloader))\n",
        "    for bi, batch in enumerate(tk0):\n",
        "        with torch.no_grad():\n",
        "            input_ids=batch['input_ids'].to(device)\n",
        "            bbox=batch['bbox'].to(device)\n",
        "            attention_mask=batch['attention_mask'].to(device)\n",
        "            token_type_ids=batch['token_type_ids'].to(device)\n",
        "            labels=batch['labels'].to(device)\n",
        "            resized_images = batch['resized_image'].to(device) \n",
        "            resized_and_aligned_bounding_boxes = batch['resized_and_aligned_bounding_boxes'].to(device)\n",
        "            outputs = model(image = resized_images,input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,labels=labels)\n",
        "            tmp_eval_loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            eval_loss += tmp_eval_loss.item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                out_label_ids = labels.detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(\n",
        "                    out_label_ids, labels.detach().cpu().numpy(), axis=0\n",
        "                )\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    preds = np.argmax(preds, axis=2)\n",
        "    out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "    preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "    for i in range(out_label_ids.shape[0]):\n",
        "        for j in range(out_label_ids.shape[1]):\n",
        "            if out_label_ids[i, j] != -100:\n",
        "                out_label_list[i].append(config.id2label[out_label_ids[i][j]])\n",
        "                preds_list[i].append(config.id2label[preds[i][j]])\n",
        "\n",
        "    results = {\n",
        "        \"loss\": eval_loss,\n",
        "        \"precision\": precision_score(out_label_list, preds_list),\n",
        "        \"recall\": recall_score(out_label_list, preds_list),\n",
        "        \"f1\": f1_score(out_label_list, preds_list),\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "BlaC10zoX2Zq"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH =\"/content/layoutlm_EuroCoorp.pt\"\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "global_step = 0\n",
        "best_f1_score = 0\n",
        "for epoch in range(5):\n",
        "    train_fn(train_dataloader, model, optimizer)\n",
        "    current_f1_score = eval_fn(valid_dataloader, model)\n",
        "    if current_f1_score[\"f1\"] > best_f1_score:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_f1_score = current_f1_score[\"f1\"]\n",
        "    print(\"best_f1_score :\", best_f1_score)"
      ],
      "metadata": {
        "id": "abSCf7GSYHBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "68e91697f32d4877b89fcedcc0a907fb",
            "bd7fb982c94449ff99d6d8eb70c64eb5",
            "d61e7ef3ca844178951902882611d6ec",
            "ed12c6da27e243e5923451a8e154529b",
            "fa5fe956945743e7ac50c2fef4b76cc1",
            "a3242a29575d4775be97f16025da73db",
            "60bc7b06f5dd4f6cbda39cdc9e4cf9a6",
            "b310db2544a747129f5a466fa531d787",
            "145f76edbb9b41559868b94842b700cb",
            "d6153110757d4d9dada32b53e78f564e",
            "8fb4b499ae814d5ba38b82fca808e2b0"
          ]
        },
        "outputId": "3b6ea769-418f-4afe-84d5-fd647fb5ae3e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68e91697f32d4877b89fcedcc0a907fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_labels [-100, 'B-produttore', 'B-produttore', 'B-produttore', 'B-produttore', 'B-produttore', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Unit.Loc.', 'B-Orario_richiesta', 'B-Orario_richiesta', 'B-Orario_richiesta', 'B-Data_richiesta', 'B-Data_richiesta', 'B-Data_richiesta', 'B-Data_richiesta', 'B-Data_richiesta', 'B-Data_richiesta', 'B-Cer', 'B-Cer', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Descrizone', 'B-Sf', 'B-Sf', 'B-Sf', 'B-Sf', 'B-Sf', 'B-Sf', 'B-Sf', 'B-Classe_Pericolo', 'B-Destino', 'B-Destino', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', 'B-Others', -100]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-7442f36cf94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcurrent_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_f1_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_f1_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-d0baf06e0793>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_dataloader, model, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-130-996b83ffc872>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# return token_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Padding of token_boxes up the bounding boxes to the sequence length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/layoutlmv2/tokenization_layoutlmv2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, boxes, word_labels, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 492\u001b[0;31m                     \u001b[0;34m\"Words must be of type `List[str]` (single pretokenized example), \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                     \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: Words must be of type `List[str]` (single pretokenized example), or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ]
    }
  ]
}