{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTg27TXL3nOe",
        "outputId": "416c0cfe-69e0-446e-aa33-0cf4412cd710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: pytesseract in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (0.3.9)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from pytesseract) (9.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install xmltodict\n",
        "# !pip install -U segmentation-models\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N53Jw_Phzk9",
        "outputId": "63df6e5c-c69f-41e6-dd46-6fcfad806ef5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!apt install tesseract-ocr\n",
        "!apt install libtesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qvYMuv3C2OmY"
      },
      "outputs": [],
      "source": [
        "import xmltodict\n",
        "import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from PIL import Image, ImageDraw\n",
        "from PIL import ImagePath \n",
        "import numpy as np\n",
        "import struct\n",
        "import binascii\n",
        "import os\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import json\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten, LSTM, BatchNormalization, ReLU, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "Image.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hzAZYHqasrZ",
        "outputId": "5cadecbe-a09c-450c-d8b2-a79660f9954b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'sudo' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (0.3.9)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from pytesseract) (9.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization,UpSampling2D\n",
        "from tensorflow.keras.layers import UpSampling2D, Input, Concatenate, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras import backend as K\n",
        "import pytesseract\n",
        "import shutil\n",
        "\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T7zc1dnJ6Rm4"
      },
      "outputs": [],
      "source": [
        "# !gdown --id \"1HZY2Q6_weEOXesvAW2STCk6qEtEjyfTY\"\n",
        "# !gdown --id \"1UYvCJqQhJz1ps8b2QxyWTvBxc_JOr9uz\"\n",
        "# !unzip -qq marmot_dataset.zip\n",
        "# !mkdir \"models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzDNOxFnhXV9",
        "outputId": "dd53b366-c639-4644-fcf5-01607202c89a"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBuWABebdYx_",
        "outputId": "f9f88a5f-aca0-48be-96d7-e15706bca74d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Aug 22 10:58:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 512.78       Driver Version: 512.78       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   59C    P8    10W /  N/A |      0MiB /  6144MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fPvpt8jCw0"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AG7iVWxyjO8-"
      },
      "outputs": [],
      "source": [
        "# originalImage = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/10.1.1.1.2006_3.bmp\"\n",
        "# imageMask = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/10.1.1.1.2006_3.xml\"\n",
        "# fileSavepath = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/\"\n",
        "# table_mask_path = \"/content/drive/MyDrive/DatasetMarmotCustom/TableMask/\"\n",
        "# col_mask_path = \"/content/drive/MyDrive/DatasetMarmotCustom/columnMask/\"\n",
        "# org_image_path = \"/content/drive/MyDrive/DatasetMarmotCustom/original images bmp/\"\n",
        "# dataPath = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hCKa8e5TjNSA"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# CREATE DATAFRAME OF PATHS.\n",
        "# dataframe\n",
        "# ---------\n",
        "# image_path, xml_path \n",
        "\n",
        "# * go through every file in mamoth folder (dataPath).\n",
        "# * check a .bmp file, extract name, check if .xml file is present or not --> store in row\n",
        "# \"\"\"\n",
        "\n",
        "# image_xml_dict = {\"image_path\":[], \"xml_path\":[],\"id\":[]}\n",
        "\n",
        "# for file in os.listdir(dataPath):\n",
        "#   if \".bmp\" in file:\n",
        "#     name = file.split(\".bmp\")[0]\n",
        "#     if os.path.exists(dataPath+name+\".xml\"):\n",
        "#       image_xml_dict['image_path'].append(name+\".bmp\")\n",
        "#       image_xml_dict['xml_path'].append(name+\".xml\")\n",
        "#       image_xml_dict['id'].append(name)\n",
        "\n",
        "\n",
        "# image_xml_df = pd.DataFrame(image_xml_dict)\n",
        "# image_xml_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EY_URd0NjEZ_"
      },
      "outputs": [],
      "source": [
        "# # /content/drive/MyDrive/case study - II/tablenet/data/final data/\n",
        "\n",
        "# def euc_dist(point1, point2):\n",
        "#     dist = np.linalg.norm(point1 - point2)\n",
        "#     return dist\n",
        "\n",
        "# def show_image_plt(image_arr):\n",
        "#   plt.figure(figsize=(5,5))\n",
        "#   plt.imshow(image_arr)\n",
        "#   plt.show()\n",
        "\n",
        "# def save_image(name, image_arr):\n",
        "#   im = Image.fromarray(image_arr)\n",
        "#   # im.save(name)\n",
        "#   im.save(name,'png')\n",
        "\n",
        "\n",
        "# final_dataframe_dict = {\"image\":[], \"table_mask\":[], \"col_mask\":[]}\n",
        "\n",
        "# for index, row in image_xml_df.iterrows():\n",
        "#     # per row --> xml_path\n",
        "#     org_img_mask_xml = row['xml_path']   # .xml path\n",
        "#     image = dataPath + row['image_path'] # image .bmp path\n",
        "\n",
        "#     # file name\n",
        "#     name = org_img_mask_xml.split(\".xml\")[0]\n",
        "    \n",
        "\n",
        "#     # reading xml file\n",
        "#     tree = ET.parse(dataPath + org_img_mask_xml)\n",
        "#     root = tree.getroot()\n",
        "\n",
        "\n",
        "#     size = root.find('size')\n",
        "#     width = int(size.find('width').text)\n",
        "#     height = int(size.find('height').text)\n",
        "#     depth = int(size.find('depth').text)\n",
        "\n",
        "#     # creating empty mask image\n",
        "#     col_mask_empty = np.zeros(shape=(height, width), dtype=np.uint8)\n",
        "#     table_mask_empty = np.zeros(shape=(height, width), dtype=np.uint8)\n",
        "\n",
        "#   # finding objects\n",
        "#     objects = tree.findall('object')\n",
        "#     table_xmin = 0\n",
        "#     table_ymin = 0\n",
        "#     table_xmax = 0\n",
        "#     table_ymax = 0\n",
        "#     prev_dist = 0\n",
        "#     dist = 0\n",
        "#     forward_flag = False\n",
        "#     backward_flag = False\n",
        "#     newtable_flag = True\n",
        "\n",
        "#     # creating empty mask image\n",
        "#     col_mask_empty = np.zeros(shape=(height, width), dtype=np.uint8)\n",
        "#     table_mask_empty = np.zeros(shape=(height, width), dtype=np.uint8)\n",
        "\n",
        "#     plt.figure(figsize=(5, 5))\n",
        "\n",
        "#     objects = tree.findall('object')\n",
        "\n",
        "#     for index, object in enumerate(objects):\n",
        "        \n",
        "#         bndbox = object.find('bndbox')\n",
        "#         xmin = int(bndbox.find('xmin').text)\n",
        "#         xmax = int(bndbox.find('xmax').text)\n",
        "#         ymin = int(bndbox.find('ymin').text)\n",
        "#         ymax = int(bndbox.find('ymax').text)\n",
        "        \n",
        "#         col_mask_empty[ymin:ymax, xmin:xmax] = 255\n",
        "        \n",
        "        \n",
        "        \n",
        "#         if index == 0:\n",
        "            \n",
        "#             prev_xmin = int(bndbox.find('xmin').text)\n",
        "#             prev_ymin = int(bndbox.find('ymin').text)\n",
        "#             prev_xmax = int(bndbox.find('xmax').text)\n",
        "#             prev_ymax = int(bndbox.find('ymax').text)\n",
        "            \n",
        "            \n",
        "#         else:  \n",
        "                \n",
        "            \n",
        "#             if xmin > prev_xmin and newtable_flag:\n",
        "                \n",
        "\n",
        "#                 table_xmin = prev_xmin\n",
        "#                 table_ymin = prev_ymin\n",
        "#                 newtable_flag = False\n",
        "#                 forward_flag = True\n",
        "#                 backward_flag = False\n",
        "\n",
        "#             if xmin < prev_xmin and newtable_flag:\n",
        "                \n",
        "                \n",
        "#                 table_xmax = prev_xmax\n",
        "#                 table_ymax = prev_ymax\n",
        "                \n",
        "                \n",
        "#                 newtable_flag = False\n",
        "#                 backward_flag = True\n",
        "#                 forward_flag = False\n",
        "\n",
        "\n",
        "\n",
        "#             if forward_flag:\n",
        "#                 dist = euc_dist(np.array([xmin, ymin]), np.array([prev_xmax, prev_ymin]))\n",
        "\n",
        "#                 if prev_dist == 0:\n",
        "#                     prev_dist = dist\n",
        "#                 else:\n",
        "\n",
        "#                     if int(np.divide(dist, prev_dist)) > 5:\n",
        "#                         newtable_flag = True\n",
        "#                         table_mask_empty[table_ymin:prev_ymax, table_xmin:prev_xmax] = 255\n",
        "\n",
        "#                         prev_dist = 0\n",
        "                        \n",
        "#                     if index==len(objects)-1:\n",
        "#                         newtable_flag = True\n",
        "#                         table_mask_empty[table_ymin:ymax, table_xmin:xmax] = 255\n",
        "\n",
        "#                         prev_dist = 0\n",
        "\n",
        "#             if backward_flag:\n",
        "#                 dist = euc_dist(np.array([xmax, ymin]), np.array([prev_xmin, prev_ymin]))\n",
        "\n",
        "#                 if prev_dist == 0:\n",
        "#                     prev_dist = dist\n",
        "#                 else:\n",
        "#                     if int(np.divide(dist, prev_dist)) > 5 or index==len(objects)-1:\n",
        "#                         newtable_flag = True\n",
        "#                         table_mask_empty[ymin:table_ymax, xmin:table_xmax] = 255\n",
        "#                         prev_dist = 0\n",
        "            \n",
        "#             prev_xmin = int(bndbox.find('xmin').text)\n",
        "#             prev_ymin = int(bndbox.find('ymin').text)\n",
        "#             prev_xmax = int(bndbox.find('xmax').text)\n",
        "#             prev_ymax = int(bndbox.find('ymax').text)\n",
        "#             prev_dist = dist\n",
        "            \n",
        "\n",
        "#     save_image(table_mask_path+ name+\".png\", table_mask_empty)\n",
        "#     save_image(col_mask_path + name+\".png\", col_mask_empty)\n",
        "\n",
        "#     final_dataframe_dict['table_mask'].append(table_mask_path+ name+\".png\")\n",
        "#     final_dataframe_dict['col_mask'].append(col_mask_path + name+\".png\")\n",
        "#     final_dataframe_dict['image'].append(image)\n",
        "\n",
        "# # creating dataframe --> (oroginal_image, table_mask, col_mask)\n",
        "# final_dataframe = pd.DataFrame(final_dataframe_dict)\n",
        "# # final_dataframe.head(2)\n",
        "# final_dataframe.to_csv(\"/content/drive/MyDrive/DatasetMarmotCustom/final_dataframe.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mpXXkfgjjKxR"
      },
      "outputs": [],
      "source": [
        "# final_dataframe = pd.read_csv(\"/content/drive/MyDrive/DatasetMarmotCustom/final_dataframe.csv\")\n",
        "# final_dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh72NVtRcwEe"
      },
      "source": [
        "# Process Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqG0vkEh7TK0"
      },
      "source": [
        "- We have manually combined the files in Marmots and Extended Marmots dataset and saved them into a final_dataset\n",
        "- final_dataset folder contains 3 folders\n",
        " 1. **table_data** : contains xml files which contain table bounding boxes. Taken from original Marmots dataset\n",
        " 2. **col_data** : contains xml files which contain table bounding boxes. Taken from original Extended Marmots dataset\n",
        " 3. **images**\n",
        "- We will use these images and create column and image masks and store them in folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sopNaWe6BYw6"
      },
      "outputs": [],
      "source": [
        "# def hex_to_float(BBox):\n",
        "#   '''\n",
        "#   Input : List of hex numbers\n",
        "#   Output : List of integers\n",
        "#   Objective : Convert hex to int format\n",
        "#   '''\n",
        "#   conv_pound = [struct.unpack('!d', bytes.fromhex(t))[0] for t in BBox]\n",
        "#   res = [round((float(x)/72)*96) for x in conv_pound]\n",
        "#   return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zyNfj8tI0VHh"
      },
      "outputs": [],
      "source": [
        "# img_paths = set(os.listdir(\"final_dataset/images\"))\n",
        "# table_data_paths = set(os.listdir(\"final_dataset/table_data\"))\n",
        "# col_data_paths = set(os.listdir(\"final_dataset/col_data\"))\n",
        "\n",
        "# def get_image_dim(image_id):\n",
        "#   img = cv2.imread(\"final_dataset/images/\"+image_id+\".bmp\")\n",
        "#   return (img.shape[0],img.shape[1])\n",
        "\n",
        "# def extract_col_mask(file_name,height=None,width=None):\n",
        "#   '''\n",
        "#   Input: file_name -> image_id without extension, dimensions of image\n",
        "#   Output: column_mask, list_of_bounding_boxes\n",
        "#   Objective: Read xml file and generate column masks. \n",
        "#         If xml file not found, return blank mask\n",
        "#   '''\n",
        "\n",
        "#   if file_name+\".xml\" not in col_data_paths:\n",
        "#     return np.array(Image.new(\"L\", (width,height))),[None]\n",
        "\n",
        "#   res = {}\n",
        "#   list_of_bounding_boxes = []\n",
        "#   try:\n",
        "#     with open(\"final_dataset/col_data/\"+file_name+\".xml\",\"r\") as f:\n",
        "#       res= xmltodict.parse(f.read())\n",
        "#   except:\n",
        "#       column_mask = np.array(Image.new(\"L\", (height,width)))\n",
        "#       return column_mask\n",
        "\n",
        "#   ht = int(res[\"annotation\"][\"size\"][\"height\"])\n",
        "#   wt = int(res[\"annotation\"][\"size\"][\"width\"])\n",
        "#   column_mask = np.array(Image.new(\"L\", (wt,ht))) # Image.new(\"\",(width, height))\n",
        "#   for bbox in res[\"annotation\"][\"object\"]:\n",
        "#     bbox = dict(bbox[\"bndbox\"])\n",
        "#     list_of_bounding_boxes.append(dict(bbox))\n",
        "#     start_point = (int(bbox[\"xmin\"]),int(bbox[\"ymin\"]))\n",
        "#     end_point = (int(bbox[\"xmax\"]),int(bbox[\"ymax\"]))\n",
        "#     column_mask = cv2.rectangle(column_mask, start_point, end_point,(255,255,255),-1)\n",
        "\n",
        "#   return column_mask, list_of_bounding_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyhLtobjRDrj"
      },
      "source": [
        "- To extract the bounding boxes from the table mask in the marmots dataset. First we need to convert the hex numbers into integers first.\n",
        "- The bonuding box attributes as relative to the CropBox and not the actual image. Marmots dataset first defines a CropBox which represents a the content area. The bounding boxes have attributes which are relative to this crop Box\n",
        "- First we extract the CropBox cordinates and then we scale the bounding box cordinates so as to fit the actual page cordinates.\n",
        "- Also we need to transfrom the bonuding box formats\n",
        " ![](https://drive.google.com/uc?export=view&id=1v--SlHMhXX3peM2-RkS1ZX3hRyjvzeRj)\n",
        " \n",
        "- **Reference** : https://stackoverflow.com/questions/52824584/do-anyone-know-how-to-extract-image-coordinate-from-marmot-dataset/53377650\n",
        ". This contains the code to convert from hex <-> int and also scaling the imaegs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XorFN1ah9BfD"
      },
      "outputs": [],
      "source": [
        "# # Ref : https://stackoverflow.com/questions/52824584/do-anyone-know-how-to-extract-image-coordinate-from-marmot-dataset/53377650\n",
        "# def extract_table_mask(file_name, height=None, width=None):\n",
        "#   '''\n",
        "#   Input: file_name -> image_id without extension, dimensions of image\n",
        "#   Output: column_mask, list_of_bounding_boxes\n",
        "#   Objective: Read xml file and generate column masks. \n",
        "#         If xml file not found, return blank mask\n",
        "#   '''\n",
        "#   if file_name+\".xml\" not in table_data_paths:\n",
        "#     return np.array(Image.new(\"L\", (width,height))),[None]\n",
        "\n",
        "#   res = {}\n",
        "#   with open(\"/content/final_dataset/table_data/\"+file_name+\".xml\") as f:\n",
        "#     res= xmltodict.parse(f.read())\n",
        "  \n",
        "#   table_bboxes = []\n",
        "#   imgw = width\n",
        "#   imgh = height\n",
        "#   table_mask = np.array(Image.new(\"L\", (imgw,imgh)))\n",
        "\n",
        "#   px0, py1, px1, py0 = hex_to_float(res[\"Page\"][\"@CropBox\"].split())\n",
        "#   pw = abs(px1 - px0)\n",
        "#   ph = abs(py1 - py0)\n",
        "#   try:\n",
        "#     test = res[\"Page\"][\"Contents\"][\"Composites\"]\n",
        "#   except:\n",
        "#     print(file_name)\n",
        "#     print(res)\n",
        "\n",
        "#   for box in res[\"Page\"][\"Contents\"][\"Composites\"]:\n",
        "#     if box['@Label'] == 'TableBody':    \n",
        "#       # if one table then box is OrderedDict else its a list of OrderedDict\n",
        "#       if isinstance(box[\"Composite\"], list):\n",
        "#         bboxes = box[\"Composite\"]\n",
        "#       else:\n",
        "#         bboxes = [box[\"Composite\"]]\n",
        "#       for single_box in bboxes:\n",
        "#         cords = single_box[\"@BBox\"].split()\n",
        "#         x0, y1, x1, y0 = hex_to_float(cords)\n",
        "#         x0 = round(imgw*(x0 - px0)/pw)\n",
        "#         x1 = round(imgw*(x1 - px0)/pw)\n",
        "#         y0 = round(imgh*(py1 - y0)/ph)\n",
        "#         y1 = round(imgh*(py1 - y1)/ph)\n",
        "\n",
        "#         table_bboxes.append({\"xmin\":x0,\"ymin\":y0,\"xmax\":x1,\"ymax\":y1})\n",
        "#         start_point = (x0,y0)\n",
        "#         end_point = (x1,y1)\n",
        "#         table_mask= cv2.rectangle(table_mask, start_point, end_point,(255,0,0),-1)\n",
        "  \n",
        "\n",
        "#   return table_mask, table_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hJsa84HVnpo_"
      },
      "outputs": [],
      "source": [
        "# data = {\"id\":[], \"col_boxes\":[],\"data\":[],\"dimensions\":[],\"img_path\":[],\"col_mask_path\":[],\"table_mask_path\":[]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WxDUbiEKCdDV"
      },
      "outputs": [],
      "source": [
        "# # Iterate through all files and then extract the table and column masks and save then \n",
        "# file_names = [x[:-4] for x in os.listdir(\"final_dataset/images\")]\n",
        "# for name in tqdm(file_names, position=0,  leave=True):\n",
        "#   ht, wt = get_image_dim(name)\n",
        "#   column_mask, col_boxes = extract_col_mask(name, ht, wt)\n",
        "#   table_mask, table_bboxes = extract_table_mask(name, ht, wt)\n",
        "  \n",
        "#   data[\"id\"].append(name)\n",
        "#   data[\"col_boxes\"].append(col_boxes)\n",
        "#   data[\"table_boxes\"].append(table_bboxes)\n",
        "#   data[\"dimensions\"].append({\"height\":ht, \"width\":wt})\n",
        "#   data[\"col_mask_path\"].append(\"final_dataset/col_masks/\"+name+\".bmp\")\n",
        "#   data[\"table_mask_path\"].append(\"final_dataset/table_masks/\"+name+\".bmp\")\n",
        "#   data[\"img_path\"].append(\"final_dataset/images\"+name+\".bmp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YTqg2fnzqlY5"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe with all the details extracted\n",
        "# df = pd.DataFrame(data)\n",
        "# df.to_csv(\"final_dataset/marmot.csv\",index=None)\n",
        "\n",
        "# df.to_csv(\"final_dataset/marmot.csv\", index=None)\n",
        "# !zip -r marmot_dataset.zip final_dataset/\n",
        "# !cp \"marmot_dataset.zip\" \"/content/drive/MyDrive/Datasets/CS2/\"\n",
        "# !cp marmot_dataset.zip \"/content/drive/MyDrive/Datasets/CS2/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVjAk7iSUudj"
      },
      "source": [
        "Final Dataset CSV file\n",
        "- **id** : image id\n",
        "- **col_boxes** : List of table bounding box cordinates\n",
        "- **table_boxes** : List of table bounding box cordinates\n",
        "- **dimensions** : width and height of image\n",
        "- **img_path** : path to image\n",
        "- **col_mask_path** : path to column masked image\n",
        "- **table_mask_path** : path to table masked image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frvurj4A12Ms"
      },
      "source": [
        "# TF DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OIkuYxQX2EHw",
        "outputId": "46ed353f-dc76-4eeb-94a3-3e1c1e4c8a4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img_path</th>\n",
              "      <th>col_mask_path</th>\n",
              "      <th>table_mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2-5</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2-4</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3-2</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2-7</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2-6</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                           img_path  \\\n",
              "0  2-5  /content/drive/Shareddrives/Data Science Team ...   \n",
              "1  2-4  /content/drive/Shareddrives/Data Science Team ...   \n",
              "2  3-2  /content/drive/Shareddrives/Data Science Team ...   \n",
              "3  2-7  /content/drive/Shareddrives/Data Science Team ...   \n",
              "4  2-6  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                       col_mask_path  \\\n",
              "0  /content/drive/Shareddrives/Data Science Team ...   \n",
              "1  /content/drive/Shareddrives/Data Science Team ...   \n",
              "2  /content/drive/Shareddrives/Data Science Team ...   \n",
              "3  /content/drive/Shareddrives/Data Science Team ...   \n",
              "4  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                     table_mask_path  \n",
              "0  /content/drive/Shareddrives/Data Science Team ...  \n",
              "1  /content/drive/Shareddrives/Data Science Team ...  \n",
              "2  /content/drive/Shareddrives/Data Science Team ...  \n",
              "3  /content/drive/Shareddrives/Data Science Team ...  \n",
              "4  /content/drive/Shareddrives/Data Science Team ...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"marmot.csv\")\n",
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=10)\n",
        "df[[\"id\",\"img_path\",\"col_mask_path\",\"table_mask_path\"]].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>col_boxes</th>\n",
              "      <th>table_boxes</th>\n",
              "      <th>dimensions</th>\n",
              "      <th>img_path</th>\n",
              "      <th>col_mask_path</th>\n",
              "      <th>table_mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2-5</td>\n",
              "      <td>[{'xmin': '44', 'ymin': '135', 'xmax': '145', ...</td>\n",
              "      <td>[{'xmin': 38, 'ymin': 141, 'xmax': 1612, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2-4</td>\n",
              "      <td>[{'xmin': '44', 'ymin': '135', 'xmax': '145', ...</td>\n",
              "      <td>[{'xmin': 39, 'ymin': 129, 'xmax': 1611, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3-2</td>\n",
              "      <td>[{'xmin': '71', 'ymin': '1128', 'xmax': '291',...</td>\n",
              "      <td>[{'xmin': 61, 'ymin': 1122, 'xmax': 1357, 'yma...</td>\n",
              "      <td>{'height': 2339, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2-7</td>\n",
              "      <td>[{'xmin': '43', 'ymin': '198', 'xmax': '135', ...</td>\n",
              "      <td>[{'xmin': 38, 'ymin': 188, 'xmax': 1617, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2-6</td>\n",
              "      <td>[{'xmin': '41', 'ymin': '195', 'xmax': '142', ...</td>\n",
              "      <td>[{'xmin': 38, 'ymin': 184, 'xmax': 1612, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                          col_boxes  \\\n",
              "0  2-5  [{'xmin': '44', 'ymin': '135', 'xmax': '145', ...   \n",
              "1  2-4  [{'xmin': '44', 'ymin': '135', 'xmax': '145', ...   \n",
              "2  3-2  [{'xmin': '71', 'ymin': '1128', 'xmax': '291',...   \n",
              "3  2-7  [{'xmin': '43', 'ymin': '198', 'xmax': '135', ...   \n",
              "4  2-6  [{'xmin': '41', 'ymin': '195', 'xmax': '142', ...   \n",
              "\n",
              "                                         table_boxes  \\\n",
              "0  [{'xmin': 38, 'ymin': 141, 'xmax': 1612, 'ymax...   \n",
              "1  [{'xmin': 39, 'ymin': 129, 'xmax': 1611, 'ymax...   \n",
              "2  [{'xmin': 61, 'ymin': 1122, 'xmax': 1357, 'yma...   \n",
              "3  [{'xmin': 38, 'ymin': 188, 'xmax': 1617, 'ymax...   \n",
              "4  [{'xmin': 38, 'ymin': 184, 'xmax': 1612, 'ymax...   \n",
              "\n",
              "                        dimensions  \\\n",
              "0  {'height': 2336, 'width': 1654}   \n",
              "1  {'height': 2336, 'width': 1654}   \n",
              "2  {'height': 2339, 'width': 1654}   \n",
              "3  {'height': 2336, 'width': 1654}   \n",
              "4  {'height': 2336, 'width': 1654}   \n",
              "\n",
              "                                            img_path  \\\n",
              "0  /content/drive/Shareddrives/Data Science Team ...   \n",
              "1  /content/drive/Shareddrives/Data Science Team ...   \n",
              "2  /content/drive/Shareddrives/Data Science Team ...   \n",
              "3  /content/drive/Shareddrives/Data Science Team ...   \n",
              "4  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                       col_mask_path  \\\n",
              "0  /content/drive/Shareddrives/Data Science Team ...   \n",
              "1  /content/drive/Shareddrives/Data Science Team ...   \n",
              "2  /content/drive/Shareddrives/Data Science Team ...   \n",
              "3  /content/drive/Shareddrives/Data Science Team ...   \n",
              "4  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                     table_mask_path  \n",
              "0  /content/drive/Shareddrives/Data Science Team ...  \n",
              "1  /content/drive/Shareddrives/Data Science Team ...  \n",
              "2  /content/drive/Shareddrives/Data Science Team ...  \n",
              "3  /content/drive/Shareddrives/Data Science Team ...  \n",
              "4  /content/drive/Shareddrives/Data Science Team ...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "lUaGJDimoU65",
        "outputId": "0c47f9f3-1305-4dc6-e268-79d9640c54cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>col_boxes</th>\n",
              "      <th>table_boxes</th>\n",
              "      <th>dimensions</th>\n",
              "      <th>img_path</th>\n",
              "      <th>col_mask_path</th>\n",
              "      <th>table_mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2-7</td>\n",
              "      <td>[{'xmin': '43', 'ymin': '198', 'xmax': '135', ...</td>\n",
              "      <td>[{'xmin': 38, 'ymin': 188, 'xmax': 1617, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2-5</td>\n",
              "      <td>[{'xmin': '44', 'ymin': '135', 'xmax': '145', ...</td>\n",
              "      <td>[{'xmin': 38, 'ymin': 141, 'xmax': 1612, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2-6</td>\n",
              "      <td>[{'xmin': '41', 'ymin': '195', 'xmax': '142', ...</td>\n",
              "      <td>[{'xmin': 38, 'ymin': 184, 'xmax': 1612, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2-4</td>\n",
              "      <td>[{'xmin': '44', 'ymin': '135', 'xmax': '145', ...</td>\n",
              "      <td>[{'xmin': 39, 'ymin': 129, 'xmax': 1611, 'ymax...</td>\n",
              "      <td>{'height': 2336, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                          col_boxes  \\\n",
              "3  2-7  [{'xmin': '43', 'ymin': '198', 'xmax': '135', ...   \n",
              "0  2-5  [{'xmin': '44', 'ymin': '135', 'xmax': '145', ...   \n",
              "4  2-6  [{'xmin': '41', 'ymin': '195', 'xmax': '142', ...   \n",
              "1  2-4  [{'xmin': '44', 'ymin': '135', 'xmax': '145', ...   \n",
              "\n",
              "                                         table_boxes  \\\n",
              "3  [{'xmin': 38, 'ymin': 188, 'xmax': 1617, 'ymax...   \n",
              "0  [{'xmin': 38, 'ymin': 141, 'xmax': 1612, 'ymax...   \n",
              "4  [{'xmin': 38, 'ymin': 184, 'xmax': 1612, 'ymax...   \n",
              "1  [{'xmin': 39, 'ymin': 129, 'xmax': 1611, 'ymax...   \n",
              "\n",
              "                        dimensions  \\\n",
              "3  {'height': 2336, 'width': 1654}   \n",
              "0  {'height': 2336, 'width': 1654}   \n",
              "4  {'height': 2336, 'width': 1654}   \n",
              "1  {'height': 2336, 'width': 1654}   \n",
              "\n",
              "                                            img_path  \\\n",
              "3  /content/drive/Shareddrives/Data Science Team ...   \n",
              "0  /content/drive/Shareddrives/Data Science Team ...   \n",
              "4  /content/drive/Shareddrives/Data Science Team ...   \n",
              "1  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                       col_mask_path  \\\n",
              "3  /content/drive/Shareddrives/Data Science Team ...   \n",
              "0  /content/drive/Shareddrives/Data Science Team ...   \n",
              "4  /content/drive/Shareddrives/Data Science Team ...   \n",
              "1  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                     table_mask_path  \n",
              "3  /content/drive/Shareddrives/Data Science Team ...  \n",
              "0  /content/drive/Shareddrives/Data Science Team ...  \n",
              "4  /content/drive/Shareddrives/Data Science Team ...  \n",
              "1  /content/drive/Shareddrives/Data Science Team ...  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "uFtanmotBWuS",
        "outputId": "3c49918c-572f-44b4-d41e-9488798de348"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>col_boxes</th>\n",
              "      <th>table_boxes</th>\n",
              "      <th>dimensions</th>\n",
              "      <th>img_path</th>\n",
              "      <th>col_mask_path</th>\n",
              "      <th>table_mask_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3-2</td>\n",
              "      <td>[{'xmin': '71', 'ymin': '1128', 'xmax': '291',...</td>\n",
              "      <td>[{'xmin': 61, 'ymin': 1122, 'xmax': 1357, 'yma...</td>\n",
              "      <td>{'height': 2339, 'width': 1654}</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "      <td>/content/drive/Shareddrives/Data Science Team ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                          col_boxes  \\\n",
              "2  3-2  [{'xmin': '71', 'ymin': '1128', 'xmax': '291',...   \n",
              "\n",
              "                                         table_boxes  \\\n",
              "2  [{'xmin': 61, 'ymin': 1122, 'xmax': 1357, 'yma...   \n",
              "\n",
              "                        dimensions  \\\n",
              "2  {'height': 2339, 'width': 1654}   \n",
              "\n",
              "                                            img_path  \\\n",
              "2  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                       col_mask_path  \\\n",
              "2  /content/drive/Shareddrives/Data Science Team ...   \n",
              "\n",
              "                                     table_mask_path  \n",
              "2  /content/drive/Shareddrives/Data Science Team ...  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2BfC49NEuBl3"
      },
      "outputs": [],
      "source": [
        "# originalImage = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/10.1.1.1.2006_3.bmp\"\n",
        "# imageMask = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/10.1.1.1.2006_3.xml\"\n",
        "# fileSavepath = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/\"\n",
        "# table_mask_path = \"/content/drive/MyDrive/DatasetMarmotCustom/TableMask/\"\n",
        "# col_mask_path = \"/content/drive/MyDrive/DatasetMarmotCustom/columnMask/\"\n",
        "# org_image_path = \"/content/drive/MyDrive/DatasetMarmotCustom/original images bmp/\"\n",
        "# dataPath = \"/content/drive/MyDrive/DatasetMarmotCustom/Marmot_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BPtzougc14pk"
      },
      "outputs": [],
      "source": [
        "img_path = \"originalimage/\"\n",
        "col_mask_path = \"columnmask/\"\n",
        "table_mask_path = \"tablemask/\"\n",
        "IMG_SIZE = 800\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "def parse_image(filename):\n",
        "  filename = filename + \".bmp\"\n",
        "  image = tf.io.read_file(img_path+filename)\n",
        "  image = tf.image.decode_bmp(image, channels=3)\n",
        "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "  \n",
        "  table_mask = tf.io.read_file(table_mask_path+filename)\n",
        "  table_mask = tf.image.decode_bmp(table_mask, channels=0)\n",
        "  table_mask = tf.image.resize(table_mask, [IMG_SIZE, IMG_SIZE])\n",
        "  table_mask = table_mask/255.0\n",
        "\n",
        "  col_mask = tf.io.read_file(col_mask_path+filename)\n",
        "  col_mask = tf.image.decode_bmp(col_mask, channels=0)\n",
        "  col_mask = tf.image.resize(col_mask, [IMG_SIZE, IMG_SIZE])\n",
        "  col_mask = col_mask/255.0\n",
        "  return image, {\"col_decoder\":col_mask, \"table_decoder\":table_mask}\n",
        "\n",
        "def configure_for_performance(ds, batch_size):\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "def make_dataset(data, batch_size):\n",
        "  filenames_ds = tf.data.Dataset.from_tensor_slices(data[\"id\"].values)\n",
        "  dataloader = filenames_ds.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataloader\n",
        "  dataloader = configure_for_performance(dataloader, batch_size)\n",
        "  return dataloader, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XcEYyFnv2glF"
      },
      "outputs": [],
      "source": [
        "TRAIN_STEPS_PER_EPOCH = len(df_train) // BATCH_SIZE                        \n",
        "train_dataloader, train_dataset = make_dataset(df_train,4)\n",
        "test_dataloader, test_dataset = make_dataset(df_test,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSfZPPwkXOSo"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7zrwOF_nXuaW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "tf.keras.backend.set_image_data_format('channels_last')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iiws_VV5Ztgq"
      },
      "outputs": [],
      "source": [
        "class TableBranch(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__(name=\"col_decoder\")\n",
        "    self.conv1 = Conv2D(filters =128,kernel_size = (1, 1), activation = 'relu')\n",
        "    self.upsample1 = UpSampling2D(size=(2, 2),interpolation='bilinear')\n",
        "    self.upsample2 = UpSampling2D(size=(2, 2),interpolation='bilinear')\n",
        "    self.upsample3 = UpSampling2D(size=(2,2))\n",
        "    self.upsample4 = UpSampling2D(size=(2,2))\n",
        "    self.convtraspose = Conv2DTranspose(2,kernel_size=3,strides=2,padding='same',activation='softmax')\n",
        "  \n",
        "  def call(self, input):\n",
        "    input, pool4, pool3 = input[0],input[1], input[2]\n",
        "    conv_1 = self.conv1(input)\n",
        "    up_sample1 = self.upsample1(conv_1)\n",
        "    concat_1 = Concatenate()([pool4,up_sample1])\n",
        "\n",
        "    up_sample2 = self.upsample2(concat_1)\n",
        "    concat_2 = Concatenate()([pool3,up_sample2])\n",
        "\n",
        "    up_sample3 = self.upsample3(concat_2)\n",
        "    up_sample4 = self.upsample4(up_sample3)\n",
        "    final = self.convtraspose(up_sample4)\n",
        "    return final\n",
        "\n",
        "class ColumnBranch(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__(name=\"table_decoder\")\n",
        "    self.conv1 = Conv2D(filters =128,kernel_size = (1, 1), activation = 'relu')\n",
        "    self.conv2 = Conv2D(filters =128,kernel_size = (1, 1), activation = 'relu')\n",
        "    self.drop1 = Dropout(0.2)\n",
        "    self.upsample1 = UpSampling2D(size=(2, 2),interpolation='bilinear')\n",
        "    self.upsample2 = UpSampling2D(size=(2, 2),interpolation='bilinear')\n",
        "    self.upsample3 = UpSampling2D(size=(2,2))\n",
        "    self.upsample4 = UpSampling2D(size=(2,2))\n",
        "    self.convtraspose = Conv2DTranspose(2,kernel_size=(3,3),strides=2,padding='same',activation='softmax')\n",
        "  \n",
        "  def call(self, input):\n",
        "    input, pool4, pool3 = input[0],input[1], input[2]\n",
        "    conv_1 = self.conv1(input)\n",
        "    dropout = self.drop1(conv_1)\n",
        "    conv_2 = self.conv2(dropout)\n",
        "\n",
        "    up_sample1 = self.upsample1(conv_1)\n",
        "    concat_1 = Concatenate()([pool4,up_sample1])\n",
        "\n",
        "    up_sample2 = self.upsample2(concat_1)\n",
        "    concat_2 = Concatenate()([pool3,up_sample2])\n",
        "    up_sample3 = self.upsample3(concat_2)\n",
        "    up_sample4 = self.upsample4(up_sample3)\n",
        "    final = self.convtraspose(up_sample4)\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Sfz4Zlv7At7U"
      },
      "outputs": [],
      "source": [
        "input_layer = Input((IMG_SIZE,IMG_SIZE,3),name=\"Input_Layer\")\n",
        "vgg_19= VGG19(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=input_layer,\n",
        "    pooling=None, \n",
        "    classifier_activation=\"softmax\"\n",
        ")\n",
        "\n",
        "for layer in vgg_19.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "pool_4_op = vgg_19.get_layer(\"block4_pool\").output\n",
        "pool_3_op = vgg_19.get_layer(\"block3_pool\").output\n",
        "x = Conv2D(128, (1,1), activation='relu',name=\"block_6_conv_1\")(vgg_19.output)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(128, (1,1), activation='relu',name=\"block_6_conv_2\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "table_output = TableBranch()([x,pool_4_op,pool_3_op])\n",
        "column_output = ColumnBranch()([x,pool_4_op,pool_3_op])\n",
        "model = Model(inputs=input_layer, outputs=[table_output,column_output])\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQshBAkkOal3",
        "outputId": "a29b2a50-b36c-4623-d02c-9ff4eab221cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Input_Layer (InputLayer)       [(None, 800, 800, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 800, 800, 64  1792        ['Input_Layer[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 800, 800, 64  36928       ['block1_conv1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 400, 400, 64  0           ['block1_conv2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 400, 400, 12  73856       ['block1_pool[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 400, 400, 12  147584      ['block2_conv1[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 200, 200, 12  0           ['block2_conv2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 200, 200, 25  295168      ['block2_pool[0][0]']            \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 200, 200, 25  590080      ['block3_conv1[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 200, 200, 25  590080      ['block3_conv2[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_conv4 (Conv2D)          (None, 200, 200, 25  590080      ['block3_conv3[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 100, 100, 25  0           ['block3_conv4[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 100, 100, 51  1180160     ['block3_pool[0][0]']            \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 100, 100, 51  2359808     ['block4_conv1[0][0]']           \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 100, 100, 51  2359808     ['block4_conv2[0][0]']           \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block4_conv4 (Conv2D)          (None, 100, 100, 51  2359808     ['block4_conv3[0][0]']           \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 50, 50, 512)  0           ['block4_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 50, 50, 512)  2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 50, 50, 512)  2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 50, 50, 512)  2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv4 (Conv2D)          (None, 50, 50, 512)  2359808     ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 25, 25, 512)  0           ['block5_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " block_6_conv_1 (Conv2D)        (None, 25, 25, 128)  65664       ['block5_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 25, 25, 128)  0           ['block_6_conv_1[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_conv_2 (Conv2D)        (None, 25, 25, 128)  16512       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 25, 25, 128)  0           ['block_6_conv_2[0][0]']         \n",
            "                                                                                                  \n",
            " col_decoder (TableBranch)      (None, 800, 800, 2)  32642       ['dropout_4[0][0]',              \n",
            "                                                                  'block4_pool[0][0]',            \n",
            "                                                                  'block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " table_decoder (ColumnBranch)   (None, 800, 800, 2)  49154       ['dropout_4[0][0]',              \n",
            "                                                                  'block4_pool[0][0]',            \n",
            "                                                                  'block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,188,356\n",
            "Trainable params: 163,972\n",
            "Non-trainable params: 20,024,384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z8VjLIfeZlUY"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OOWrxHqx_WZS"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
        "# opt = tf.keras.optimizers.Adam(learning_rate=0.01) \n",
        "\n",
        "losses = {\n",
        "    \"table_decoder\":\"sparse_categorical_crossentropy\",\n",
        "    \"col_decoder\": \"sparse_categorical_crossentropy\"\n",
        "}\n",
        "\n",
        "model.compile(loss=losses, optimizer=opt,run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "qqQK-Ta1KHmO",
        "outputId": "82dbc982-a52b-48e9-c7ea-e75325a67b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['table_decoder/conv2d_5/kernel:0', 'table_decoder/conv2d_5/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "1/1 [==============================] - 112s 112s/step - loss: 536.7637 - col_decoder_loss: 263.6639 - table_decoder_loss: 273.0998\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x284a5c8ae20>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Model checkpoint callback\n",
        "file_path = \"CS2_1024_00_{epoch:04d}.hdf5\"\n",
        "\n",
        "cp_callback= tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=file_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    period=5)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_dataloader,\n",
        "    steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n",
        "    epochs=1,\n",
        "    callbacks=[cp_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wLtfgdXqVKF"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/final_dataset/Datasets/CS2/CS2_1024_00_0005.hdf5\")\n",
        "# # !cp \"models/CS2_1024_00_0020.hdf5\" \"/content/drive/MyDrive/Datasets/CS2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zicVnDrFMUPa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer with unsupported characters which will be renamed to input_layer in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 31). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "tf.keras.models.save_model(model, './saved_model')\n",
        "my_tf_saved_model = tf.keras.models.load_model('./saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh2zPk7lbPDA"
      },
      "outputs": [],
      "source": [
        "# !cp tablenet_model.zip \"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/final_dataset/Datasets/CS2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BqFoKQHJ_TnP"
      },
      "outputs": [],
      "source": [
        "# given predicted boxes approximate the predicted rectangles\n",
        "def fil_approx_boxes(img):\n",
        "  cv2.imwrite(\"test.jpeg\",img)\n",
        "  img = cv2.imread(\"test.jpeg\",0)\n",
        "  img = cv2.medianBlur(img,5)\n",
        "  img = cv2.GaussianBlur(img,(13,13),0)\n",
        "  img = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "  # convert to grayscale thresholds and find contours\n",
        "  _, threshold = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY_INV)\n",
        "  contours,_ = cv2.findContours(threshold, cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
        "  for cnt in contours:\n",
        "      # plot a bounding box around contours and fill it\n",
        "      x,y,w,h = cv2.boundingRect(cnt)\n",
        "      if x==0 or y==0:\n",
        "          continue \n",
        "      # if cv2.contourArea(cnt) < 5000:\n",
        "      #   continue\n",
        "      cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),-1)\n",
        "      \n",
        "  # Remove small dots in image\n",
        "  img = cv2.GaussianBlur(img,(13,13),0)\n",
        "  img = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)[1]\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0lwdsLh2bKvr"
      },
      "outputs": [],
      "source": [
        "# predict table and column masks and display\n",
        "def plot_res(img,masks=None,ind=0):\n",
        "\n",
        "  res1, res2 = model.predict(np.array([img]))\n",
        "  res1 =  np.expand_dims(np.argmax(res1[0], axis=-1), axis=-1)\n",
        "  res2 = np.expand_dims(np.argmax(res2[0], axis=-1), axis=-1)\n",
        "  pred_col = np.squeeze(np.where(res1==1,255,0))\n",
        "  pred_table = np.squeeze(np.where(res2==1,255,0))\n",
        "\n",
        "  if masks is None:\n",
        "    return fil_approx_boxes(pred_table),fil_approx_boxes(pred_col)\n",
        "\n",
        "  fig, ax = plt.subplots(1,6,figsize=(20,20))\n",
        "  ax[0].imshow(np.squeeze(np.where(masks[\"table_decoder\"]==1,255,0)))\n",
        "  ax[0].title.set_text(\"Table Mask\")\n",
        "  ax[1].imshow(np.squeeze(np.where(masks[\"col_decoder\"]==1,255,0)))\n",
        "  ax[1].title.set_text(\"Column Mask\")\n",
        "  \n",
        "  ax[2].imshow(pred_table)\n",
        "  ax[2].title.set_text(\"Predicted Table Mask\")\n",
        "  ax[3].imshow(pred_col)\n",
        "  ax[3].title.set_text(\"Predicted Column Mask\")\n",
        "\n",
        "  ax[4].imshow(fil_approx_boxes(pred_table))\n",
        "  ax[4].title.set_text(\"Approximated Table Mask\")\n",
        "  ax[5].imshow(fil_approx_boxes(pred_col))\n",
        "  ax[5].title.set_text(\"Approximated Column Mask\")\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "  return fil_approx_boxes(pred_table),fil_approx_boxes(pred_col)\n",
        "\n",
        "def plot_masks(file_id):\n",
        "  fig, ax = plt.subplots(1,3,figsize=(7,7))\n",
        "  ax[0].imshow(cv2.imread(\"final_dataset/images/\"+id+\".bmp\"))\n",
        "  ax[0].title.set_text(\"Image\")\n",
        "  ax[1].imshow(cv2.imread(\"output/true/\"+id+\".bmp\"))\n",
        "  ax[1].title.set_text(\"Ground Truth Mask\")\n",
        "  ax[2].imshow(cv2.imread(\"output/pred/\"+id+\".jpeg\"))\n",
        "  ax[2].title.set_text(\"Predicted Mask\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvWjPlMuhDQ0"
      },
      "source": [
        "## Images from train_dataset (SEEN SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "are-aOmuhFhr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "# table auto predict : 40-45,45-50\n",
        "\n",
        "count = 0\n",
        "for img, mask in train_dataset.take(80):\n",
        "  # print(count)\n",
        "  count += 1\n",
        "  if count > 45 and count<50:\n",
        "    plot_res(img, mask, count) \n",
        "\n",
        "print(count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkhnu20Ng-98"
      },
      "source": [
        "## Images from test_dataset (UNSEEN SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MggvWUGtMBsr"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for img, mask in test_dataset.take(50):\n",
        "  # print(count)\n",
        "  count += 1\n",
        "  if count > 17 and count<22:\n",
        "    plot_res(img, mask,count) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALu_29GnEjxO"
      },
      "source": [
        "## OBSERVATIONS\n",
        "- The model was trained for 100 epochs. After prediction we have defined a function called *fill_aprox_boxes* function, in which we use opencv functions to remove minor noises as well as trying to approximate the unevenly shaped rectangle shapes\n",
        "- From predictions of on both train and test dataset samples, we can seee that our model predicts Table masks almost accurately. There are very few misclassifications. But, it doesnt properly predict the test dataset images which are unseen.\n",
        "- We see that on test dataset(unseen images) our model still predicts table masks pretty well.\n",
        "- **Interesting observation**: <br>\n",
        " - We had seen in EDA part that some images have column masks but no column masks (this was bcause it was not annotated). When we try to predict those images, we see that table region was predicted accurately even though for those image we didnt provide image masks.\n",
        " - This is becuase our model takes into account both column and table masks while predicting the masks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NECnqweeV35"
      },
      "source": [
        "## Predict table masks and extract text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JcxLTkPVxQxz"
      },
      "outputs": [],
      "source": [
        "def predict_and_extract(file_path, output_file_name = \"res.txt\"):\n",
        "  '''\n",
        "  Steps done:\n",
        "  1) Read image and resize it to (800,800)\n",
        "  2) Predict table_masks using model\n",
        "  3) Resize the table_masks to be same size as original image\n",
        "  4) Extract text from only the table_region & save in a txt file\n",
        "  '''\n",
        "  \n",
        "  img_path = file_path\n",
        "  image = tf.io.read_file(img_path)\n",
        "  org_image = tf.image.decode_bmp(image, channels=3)\n",
        "  h,w = org_image.shape[0],org_image.shape[1]\n",
        "  image = tf.image.resize(org_image, [IMG_SIZE, IMG_SIZE])\n",
        "  pred_table, pred_col = plot_res(image,masks=None)\n",
        "\n",
        "  # Create mask from predicted table_mask\n",
        "  tab = np.where(pred_table == 0,0,1)\n",
        "  mask = np.expand_dims(tab,axis=2)\n",
        "  mask = np.concatenate((mask,mask,mask),axis=2)\n",
        "  cv2.imwrite(\"mask.jpeg\",mask)\n",
        "\n",
        "  # resize mask to original image dimension (To get better results in tesseract)\n",
        "  mask = cv2.resize(cv2.imread(\"mask.jpeg\"), (w,h), interpolation = cv2.INTER_AREA)\n",
        "  masked_img= org_image.numpy() * mask\n",
        "  cv2.imwrite(\"org.jpeg\",masked_img)\n",
        "\n",
        "  data = pytesseract.image_to_string(Image.open('org.jpeg'), lang='eng')\n",
        "  print(\"Extracted DATA:\\n \",data)\n",
        "\n",
        "  cv2.imshow('',masked_img)\n",
        "\n",
        "  file1 = open(output_file_name,\"w\")\n",
        "  file1.write(data)\n",
        "  file1.close()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "hsXYVx6M_Xy6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (9.2.0)\n",
            "Requirement already satisfied: image in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (1.5.33)\n",
            "Requirement already satisfied: django in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from image) (4.1)\n",
            "Requirement already satisfied: pillow in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from image) (9.2.0)\n",
            "Requirement already satisfied: six in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from image) (1.16.0)\n",
            "Requirement already satisfied: tzdata in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from django->image) (2022.2)\n",
            "Requirement already satisfied: backports.zoneinfo in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from django->image) (0.2.1)\n",
            "Requirement already satisfied: sqlparse>=0.2.2 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from django->image) (0.4.2)\n",
            "Requirement already satisfied: asgiref<4,>=3.5.2 in c:\\users\\jyoti\\anaconda3\\envs\\tf_2.4\\lib\\site-packages (from django->image) (3.5.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow\n",
        "!pip install image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UemP7uB2UJ3o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "Extracted DATA:\n",
            "  allet No. Type Width (\n",
            "\n",
            "600\n",
            "\n",
            "H10 21P3034}\n",
            "H10 21P3034|\n",
            "\n",
            "M10 21P3034]\n",
            "\n",
            "M10 21P303:\n",
            "\n",
            "M10 21P3034\n",
            "\n",
            "Pallet Dimension\n",
            "\n",
            "Length(Mtr.)\n",
            "\n",
            "Joint\n",
            "\n",
            "PALLET WT\n",
            "\n",
            "Gross Wt.\n",
            "\n",
            "851.600\n",
            "\n",
            "436.600\n",
            "\n",
            "391.200\n",
            "\n",
            "786.400\n",
            "430.500\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# from PIL import TiffImagePlugin\n",
        "from PIL import Image\n",
        "# import Image\n",
        "predict_and_extract(\"2-3.bmp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crCcTFVAKBlJ"
      },
      "source": [
        "# Post Training Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFCakY_G2XOJ"
      },
      "outputs": [],
      "source": [
        "!mkdir output\n",
        "!mkdir output/true\n",
        "!mkdir output/pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkjPJ3IBgAoo"
      },
      "outputs": [],
      "source": [
        "def predict_and_save(file_id, output_folder):\n",
        "  '''\n",
        "  Fetch the image from the file_id and predict masks\n",
        "  Save the ground truth and predicted masks in the output_folder\n",
        "  '''\n",
        "  img_path = \"/content/drive/MyDrive/final_dataset/images/\"+file_id+\".bmp\"\n",
        "  gt_mask_path = \"/content/drive/MyDrive/final_dataset/table_masks/\"+file_id+\".bmp\"\n",
        "  output_mask_path = output_folder+\"/pred/\"+file_id+\".jpeg\" \n",
        "\n",
        "  true_path = output_folder+\"/true/\"\n",
        "  !cp $gt_mask_path $true_path\n",
        "\n",
        "  image = tf.io.read_file(img_path)\n",
        "  org_image = tf.image.decode_bmp(image, channels=3)\n",
        "  image = tf.image.resize(org_image, [IMG_SIZE, IMG_SIZE])\n",
        "  pred_table, pred_col = plot_res(image,masks=None)\n",
        "  h,w,_ = cv2.imread(gt_mask_path).shape \n",
        "  mask = cv2.resize(pred_table, (w,h), interpolation = cv2.INTER_AREA)\n",
        "  cv2.imwrite(output_mask_path,mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ3JM-spLBAY"
      },
      "outputs": [],
      "source": [
        "for id in tqdm(df[\"id\"].values):\n",
        "  predict_and_save(id, 'output')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ8V9xmoSm2R"
      },
      "source": [
        "## Check loss for each predictions\n",
        "- We get the predicted masks for each image and save into separate folders\n",
        "- We then calculate the IoU score foe the ground truth mask and the predicted mask\n",
        "- We find that in cases where there were no tables (i.e mask is blank) we get IoU as NaN or 0. We ignore those cases for analysis\n",
        "- We divide the samples into 3 categories based on the IoU score\n",
        "  1. **Best** : IoU score > 0.7\n",
        "  2. **Average** : IoU score between 0.4 and 0.7\n",
        "  3. **Worst** : IoU score < 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTn7gZnKRW21"
      },
      "outputs": [],
      "source": [
        "# IoU calculation\n",
        "result1 = cv2.imread(\"/content/output/true/10.1.1.1.2006_3.bmp\")\n",
        "result2 = cv2.imread(\"/content/output/pred/10.1.1.1.2006_3.jpeg\")\n",
        "\n",
        "data = []\n",
        "for id in tqdm(df[\"id\"].values):\n",
        "  img1 = cv2.imread(\"output/true/\"+id+\".bmp\")\n",
        "  img2 = cv2.imread(\"output/pred/\"+id+\".jpeg\")\n",
        "  \n",
        "  intersection = np.logical_and(img1, img2)\n",
        "  union = np.logical_or(img1, img2)\n",
        "  iou_score = np.sum(intersection) / np.sum(union)\n",
        "  data.append((id,iou_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb4mKjBgai8u"
      },
      "outputs": [],
      "source": [
        "df_loss = pd.DataFrame(data=data, columns=[\"id\",\"iou_score\"])\n",
        "\n",
        "# IoU is NaN or 0 for images with no tables/columns\n",
        "df_nan = df_loss[(df_loss[\"iou_score\"].isna()) | (df_loss[\"iou_score\"] == 0)]\n",
        "\n",
        "df_loss = df_loss.dropna() \n",
        "df_loss = df_loss[df_loss[\"iou_score\"]>0]\n",
        "df_loss = df_loss.sort_values(by=\"iou_score\",ascending=False)\n",
        "df_loss.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQqxtD3NAMk9"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df_loss[\"iou_score\"])\n",
        "plt.title(\"Distribution of IoU scores\")\n",
        "percentile_25 = np.percentile(df_loss[\"iou_score\"],25)\n",
        "percentile_75 = np.percentile(df_loss[\"iou_score\"],75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGDUelF5ar0k"
      },
      "outputs": [],
      "source": [
        "df_best = df_loss[df_loss[\"iou_score\"] > 0.7]\n",
        "df_worst = df_loss[df_loss[\"iou_score\"] < 0.3]\n",
        "df_avg = df_loss[(df_loss[\"iou_score\"] > 0.4) & ((df_loss[\"iou_score\"] < 0.7))]\n",
        "\n",
        "print(\"Best IoU score : \",max(df_loss[\"iou_score\"].values))\n",
        "print(\"Best IoU score : \",min(df_loss[\"iou_score\"].values))\n",
        "\n",
        "print(\"No of images in Best cat \",df_best.shape[0])\n",
        "print(\"No of images in Avg preds cat:\",df_avg.shape[0])\n",
        "print(\"No of images in Worst preds cat:\",df_worst.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgLvqbKwCbt8"
      },
      "outputs": [],
      "source": [
        "# Best cases\n",
        "for id in df_best.iloc[:5][\"id\"].values:\n",
        "  plot_masks(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSHVE4AsDY9T"
      },
      "outputs": [],
      "source": [
        "# Average cases\n",
        "for id in df_avg.iloc[30:35][\"id\"].values:\n",
        "  plot_masks(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLYJgMvDDhOA"
      },
      "outputs": [],
      "source": [
        "# Worst cases\n",
        "for id in df_worst.iloc[:6][\"id\"].values:\n",
        "  plot_masks(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRSIUXt91Gl-"
      },
      "outputs": [],
      "source": [
        "# IoU Nan\n",
        "for id in df_nan.iloc[:5][\"id\"].values:\n",
        "  plot_masks(id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLGFantg7A81"
      },
      "source": [
        "## **Observations**\n",
        "\n",
        "**Distribution of the scores**\n",
        "- We can see that out distribution of IoU scores is skewed towards the left i.e most values fall on the right side. This is a good thing as we can see that most scores are > 0.4 and very few scores < 0.3. Generally, IoU score of 0.5 is considered fairly good.\n",
        "- We categorize our samples into categories based on the IoU scores\n",
        "      1.Best : IoU score > 0.7\n",
        "      2.Average : IoU score between 0.4 and 0.7\n",
        "      3.Worst : IoU score < 0.4\n",
        "\n",
        "- We see that out of 467 samples 87% of the images belonged to Best category, 12% in the average and only 1% in the worst category. This seems like a fairly good distribution in our case.\n",
        "\n",
        "**Looking at images in the categories**\n",
        "1. **BEST**\n",
        "  - Most of these images have only 1 table\n",
        "  - The tables are larger in size and occupy a mmajor part of the iamge size.\n",
        "  - Also, when we look at the actual image as the size of the tables are large, there is very less text in the image exclusing the tables.\n",
        "\n",
        "2. **AVERAGE**\n",
        "  - We have multiple tables in a single image\n",
        "  - Compared to BEST cases, the table sizes are significatly smaller.\n",
        "  - Our model fails in cases where tables are adjacent to once another. In such cases we see that our model combines the masks of adjacent tables into one single table.\n",
        "  - In some cases whitespace surrounding a table is also predicted as mask, because of which the predicted mask is slightly larger than the ground truth masks.\n",
        "\n",
        "3. **WORST CASES**\n",
        "  - We see that if table sizes are very small i.e small height, the our models fails to predict the masks properly.\n",
        "\n",
        "4. **IoU = 0 or NaN**\n",
        "\n",
        "  - As we assumed before that if IoU score is NaN or 0 its because there were no tables in the image. When we plot the images with IoU as NaN we see the same.\n",
        "  - For some images we see that even though there were no tables, some tiny dots were predicted becuase of which IoU was 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_Mx-r-idpi"
      },
      "source": [
        "# Inference Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwxv_qaSifMs"
      },
      "outputs": [],
      "source": [
        "os.mkdir(\"./temp\")\n",
        "os.mkdir(\"./output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XCy_rXHilNU"
      },
      "outputs": [],
      "source": [
        "# Save data into respective CSV Files\n",
        "def save_to_csv(csv_name,data):\n",
        "  delim = \"|\"\n",
        "  # if data.find(\",\") != -1:\n",
        "  #   delim = \",\"\n",
        "  # elif data.find(\"|\") != -1:\n",
        "  #   delim = \"|\"\n",
        "\n",
        "  data_arr = data.split(\"\\n\")\n",
        "  data_arr = [arr for arr in data_arr if len(arr.strip()) != 0]\n",
        "  with open(csv_name+\".csv\",'w') as file:\n",
        "    for line in data_arr:\n",
        "      line = line.replace(delim,\",\")\n",
        "      file.write(line+\"\\n\")\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvUqKN5Pilph"
      },
      "outputs": [],
      "source": [
        "#  Given masked image, Save both tables and extract text from each\n",
        "def extract_text(img_path='/content/temp/final_masked.jpeg'):\n",
        "  print(\"Extracting Text....\")\n",
        "  img = cv2.imread(img_path,0)\n",
        "  print('img....',img)\n",
        "  org_img = img\n",
        "  # img = cv2.GaussianBlur(img,(10,10),0)\n",
        "  img = cv2.threshold(img, 0,255, cv2.THRESH_BINARY)[1]\n",
        "  kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "\n",
        "  _, threshold = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY_INV)\n",
        "  contours,_ = cv2.findContours(threshold, cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
        "  idx = 1\n",
        "  for cnt in contours:\n",
        "    file_name = \"output/Table_\"+str(idx)\n",
        "    x,y,w,h = cv2.boundingRect(cnt)\n",
        "    if x==0 or y==0 or w*h < 20000:\n",
        "        continue\n",
        "\n",
        "    roi = org_img[y:y+h, x:x+w]\n",
        "    roi = cv2.filter2D(roi, -1, kernel)\n",
        "    roi = cv2.resize(roi, (int(w*1.25),int(h*1.25)), interpolation = cv2.INTER_AREA)\n",
        "    cv2_imshow(roi)\n",
        "    data = pytesseract.image_to_string(roi,config='--psm 6',lang='eng')\n",
        "    print(\"Extracted Text: \",data)\n",
        "    cv2.imwrite(file_name+\".jpeg\",roi) \n",
        "    save_to_csv(file_name,data)\n",
        "\n",
        "    idx += 1\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxBf8Z36ioJc"
      },
      "outputs": [],
      "source": [
        "# predict table and column masks and display\n",
        "def predict_table_masks(img):\n",
        "  res1, res2 = model.predict(np.array([img]))\n",
        "  res1 =  np.expand_dims(np.argmax(res1[0], axis=-1), axis=-1)\n",
        "  res2 = np.expand_dims(np.argmax(res2[0], axis=-1), axis=-1)\n",
        "  pred_col = np.squeeze(np.where(res1==1,255,0))\n",
        "  pred_table = np.squeeze(np.where(res2==1,255,0))\n",
        "\n",
        "  fig, ax = plt.subplots(1,2,figsize=(7,7))\n",
        "  ax[0].imshow(pred_table)\n",
        "  ax[0].title.set_text(\"Predicted Table\")\n",
        "  ax[1].imshow(fil_approx_boxes(pred_table))\n",
        "  ax[1].title.set_text(\"Proccsed Mask\")\n",
        "  plt.show()\n",
        "\n",
        "  return fil_approx_boxes(pred_table),fil_approx_boxes(pred_col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXL9qxWdircz"
      },
      "outputs": [],
      "source": [
        "# Predict masks and extract text\n",
        "def predict_and_extract(img_path):\n",
        "  for file_name in os.listdir(\"output\"):\n",
        "    os.remove(\"output/\"+file_name)\n",
        "\n",
        "  image = tf.io.read_file(img_path)\n",
        "  org_image = tf.image.decode_image(image, channels=3)\n",
        "  h,w = org_image.shape[0],org_image.shape[1]\n",
        "\n",
        "  image = tf.image.resize(org_image, [800, 800])\n",
        "  cv2_imshow(cv2.resize(cv2.imread(img_path),(600,600)))\n",
        "  pred_table, pred_col = predict_table_masks(image)\n",
        "  tab = np.where(pred_table == 0,0,1)\n",
        "  mask = np.expand_dims(tab,axis=2)\n",
        "  mask = np.concatenate((mask,mask,mask),axis=2)\n",
        "  cv2.imwrite(\"temp/mask.jpeg\",mask)\n",
        "\n",
        "  mask = cv2.resize(cv2.imread(\"temp/mask.jpeg\"), (w,h), interpolation = cv2.INTER_AREA)\n",
        "  masked_img= org_image.numpy() * mask\n",
        "  cv2_imshow(masked_img)\n",
        "  cv2.imwrite(\"/content/temp/final_masked.jpeg\",masked_img)\n",
        "  extract_text()\n",
        "  shutil.make_archive('output', 'zip', \"output/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gduXGKqitg-"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/4-04.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyHTcoaHiwI0"
      },
      "source": [
        "In the output folder we would get individual images of all the individual tables as well as the csv files containing the extracted csv files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqxgScduFzf2"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yC9PmEVGITn"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-3.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmDtrGnlGL2c"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-4.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2p62NOKGSK9"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-5.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpa4X3XyGYsP"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-6.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEHqU6MGGeiz"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-7.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__tu-vdlGfrT"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/2-8.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPimt8OBGhCw"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/3-2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRer8f7_Gic9"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/4-04.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwibaQm8Gk3o"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/4-05.PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMbspxf3GnZv"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/5-03.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35F5zpmrGqNr"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/5-04.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D5AVPItGsy8"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/6-3.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ra8xePsXewD"
      },
      "source": [
        "## 300 dpi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m6j-m2IKwzD"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-2page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoNomJtVOwWD"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-3page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDPjBNlCu8IS"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-4page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVPhglHcu-iI"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-5page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-cYIUt1vAyt"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-6page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3SBGf73vE7Q"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-7page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H92KPylKvI1Z"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/2-8page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVYNVi-AvMdS"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/4-4page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isMiKy5AvPkS"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/4-5page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-N6n_OVvTYE"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/5-3page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUpf8J-_vXCi"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/5-4page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De6d0Hm0valn"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/6-3page-0.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-jclGbM5DAz"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/BRIC_S FATT + PL (SI21307931 CHENNAI)page-9.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5LNLZXi6q-E"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/BRIC_S FATT + PL (SI21307931 CHENNAI)page-5.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v_Hp6Wf8S8e"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/BRIC_S FATT + PL (SI21307931 CHENNAI)page-6.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_aDCmOY8TfA"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/BRIC_S FATT + PL (SI21307931 CHENNAI)page-7.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU4A7wmC8T4H"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/BRIC_S FATT + PL (SI21307931 CHENNAI)page-7.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHB7eYaz8UOZ"
      },
      "outputs": [],
      "source": [
        "predict_and_extract(\"/content/drive/Shareddrives/Data Science Team folder-open/Jyoti/tabulardatadpi/300dpi (1)/300dpi/BRIC_S FATT + PL (SI21307931 CHENNAI)page-9.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TableNet_Complete_(1).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.0 ('tf_2.4')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "66a7d7a70b884a83c58e61e4528d694246f1dbc2d49093ee9a196981d1ace10b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
